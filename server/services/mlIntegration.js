/**
 * ML Integration Service
 * Integrates with the Python ML service for enhanced predictions
 */

const axios = require('axios');
const logger = require('../utils/logger') || console;

class MLIntegrationService {
  constructor() {
    this.mlServiceUrl = process.env.ML_SERVICE_URL || 'http://localhost:8001';
    this.timeout = 30000; // 30 seconds
    this.retryAttempts = 3;
  }

  /**
   * Get enhanced predictions from ML service
   * @param {Object} location - Location coordinates
   * @param {string} timeframe - Prediction timeframe
   * @param {Object} options - Additional options
   * @returns {Promise<Object>} Enhanced predictions
   */
  async getEnhancedPredictions(location, timeframe = '7_days', options = {}) {
    try {
      logger.info(`ü§ñ Requesting enhanced predictions from ML service for location: ${JSON.stringify(location)}`);

      const requestData = {
        location: {
          lat: parseFloat(location.lat || location.latitude),
          lng: parseFloat(location.lng || location.longitude)
        },
        timeframe,
        include_weather: options.includeWeather !== false,
        include_historical: options.includeHistorical !== false
      };

      const response = await this.makeRequest('/predict', requestData);

      if (response.success) {
        logger.info(`‚úÖ Enhanced predictions received: ${response.predictions?.length || 0} predictions, ${response.risk_areas?.length || 0} risk areas`);
        return {
          success: true,
          data: {
            predictions: response.predictions || [],
            risk_areas: response.risk_areas || [],
            overall_risk_score: response.overall_risk_score || 0,
            weather_context: response.weather_context,
            historical_context: response.historical_context,
            model_info: response.model_info,
            generated_at: response.generated_at
          }
        };
      } else {
        logger.warn(`‚ö†Ô∏è ML service returned unsuccessful response: ${response.message}`);
        return {
          success: false,
          message: response.message || 'ML service returned unsuccessful response',
          data: null
        };
      }

    } catch (error) {
      logger.error(`‚ùå Error getting enhanced predictions: ${error.message}`);
      
      // Return fallback predictions if ML service is unavailable
      return this.getFallbackPredictions(location, timeframe, options);
    }
  }

  /**
   * Get risk heatmap data from ML service
   * @param {Object} centerLocation - Center coordinates
   * @param {number} radiusKm - Radius in kilometers
   * @param {number} resolution - Grid resolution
   * @returns {Promise<Object>} Heatmap data
   */
  async getRiskHeatmap(centerLocation, radiusKm = 10, resolution = 100) {
    try {
      logger.info(`üó∫Ô∏è Requesting risk heatmap from ML service`);

      const response = await this.makeRequest('/visualization/heatmap', {
        center_lat: parseFloat(centerLocation.lat || centerLocation.latitude),
        center_lng: parseFloat(centerLocation.lng || centerLocation.longitude),
        radius_km: radiusKm,
        resolution
      });

      if (response.success) {
        logger.info(`‚úÖ Risk heatmap received: ${response.heatmap_data?.length || 0} data points`);
        return {
          success: true,
          data: response.heatmap_data || [],
          bounds: response.bounds,
          center: centerLocation,
          radius_km: radiusKm,
          resolution
        };
      } else {
        logger.warn(`‚ö†Ô∏è Heatmap generation failed: ${response.message}`);
        return {
          success: false,
          message: response.message,
          data: null
        };
      }

    } catch (error) {
      logger.error(`‚ùå Error getting risk heatmap: ${error.message}`);
      return {
        success: false,
        message: 'Failed to generate heatmap',
        data: null
      };
    }
  }

  /**
   * Get trend analysis from ML service
   * @param {Object} location - Location coordinates
   * @param {string} timeframe - Analysis timeframe
   * @returns {Promise<Object>} Trend data
   */
  async getTrendAnalysis(location, timeframe = '30_days') {
    try {
      logger.info(`üìä Requesting trend analysis from ML service`);

      const response = await this.makeRequest('/visualization/trends', {
        location: {
          lat: parseFloat(location.lat || location.latitude),
          lng: parseFloat(location.lng || location.longitude)
        },
        timeframe
      });

      if (response.success) {
        logger.info(`‚úÖ Trend analysis received`);
        return {
          success: true,
          data: response.trends || {},
          summary: response.summary || {},
          timeframe
        };
      } else {
        logger.warn(`‚ö†Ô∏è Trend analysis failed: ${response.message}`);
        return {
          success: false,
          message: response.message,
          data: null
        };
      }

    } catch (error) {
      logger.error(`‚ùå Error getting trend analysis: ${error.message}`);
      return {
        success: false,
        message: 'Failed to generate trend analysis',
        data: null
      };
    }
  }

  /**
   * Check ML service health
   * @returns {Promise<Object>} Health status
   */
  async checkHealth() {
    try {
      const response = await this.makeRequest('/health', {}, 'GET');
      
      return {
        success: true,
        status: response.status || 'unknown',
        models_loaded: response.models_loaded || 0,
        timestamp: response.timestamp
      };

    } catch (error) {
      logger.error(`‚ùå ML service health check failed: ${error.message}`);
      
      // Check if it's a connection error
      if (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND') {
        return {
          success: false,
          status: 'unreachable',
          error: 'ML service is not running or not accessible'
        };
      }
      
      return {
        success: false,
        status: 'unhealthy',
        error: error.message
      };
    }
  }

  /**
   * Get model status
   * @returns {Promise<Object>} Model status information
   */
  async getModelStatus() {
    try {
      const response = await this.makeRequest('/models/status');
      
      return {
        success: true,
        models: response.models || {},
        timestamp: new Date().toISOString()
      };

    } catch (error) {
      logger.error(`‚ùå Error getting model status: ${error.message}`);
      return {
        success: false,
        error: error.message,
        models: {}
      };
    }
  }

  /**
   * Trigger model retraining
   * @returns {Promise<Object>} Training status
   */
  async retrainModels() {
    try {
      logger.info(`üîÑ Triggering model retraining`);
      
      const response = await this.makeRequest('/train', {}, 'POST');
      
      return {
        success: true,
        status: response.status || 'training',
        message: response.message || 'Model training started'
      };

    } catch (error) {
      logger.error(`‚ùå Error triggering model retraining: ${error.message}`);
      return {
        success: false,
        error: error.message
      };
    }
  }

  /**
   * Make HTTP request to ML service with retry logic
   * @param {string} endpoint - API endpoint
   * @param {Object} data - Request data
   * @param {string} method - HTTP method
   * @param {number} attempt - Current attempt number
   * @returns {Promise<Object>} Response data
   */
  async makeRequest(endpoint, data = {}, method = 'POST', attempt = 1) {
    try {
      const url = `${this.mlServiceUrl}${endpoint}`;
      
      const config = {
        method,
        url,
        timeout: this.timeout,
        headers: {
          'Content-Type': 'application/json'
        }
      };

      if (method === 'POST') {
        config.data = data;
      } else if (method === 'GET') {
        if (data && Object.keys(data).length > 0) {
          config.params = data;
        }
      }

      logger.info(`üåê Making ${method} request to ML service: ${url}`);
      const response = await axios(config);
      
      return response.data;

    } catch (error) {
      logger.error(`‚ùå Request to ML service failed (attempt ${attempt}): ${error.message}`);
      
      // Retry logic
      if (attempt < this.retryAttempts && this.isRetryableError(error)) {
        logger.info(`üîÑ Retrying request (attempt ${attempt + 1}/${this.retryAttempts})`);
        await this.delay(1000 * attempt); // Exponential backoff
        return this.makeRequest(endpoint, data, method, attempt + 1);
      }
      
      throw error;
    }
  }

  /**
   * Check if error is retryable
   * @param {Error} error - Error object
   * @returns {boolean} Whether error is retryable
   */
  isRetryableError(error) {
    if (!error.response) {
      return true; // Network errors are retryable
    }
    
    const status = error.response.status;
    return status >= 500 || status === 408 || status === 429;
  }

  /**
   * Delay execution
   * @param {number} ms - Milliseconds to delay
   * @returns {Promise<void>}
   */
  delay(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  /**
   * Get fallback predictions when ML service is unavailable
   * @param {Object} location - Location coordinates
   * @param {string} timeframe - Prediction timeframe
   * @param {Object} options - Additional options
   * @returns {Object} Fallback predictions
   */
  getFallbackPredictions(location, timeframe, options) {
    logger.info(`üîÑ Using fallback predictions (ML service unavailable)`);

    // Simple fallback predictions based on heuristics
    const predictions = [
      {
        category: 'Road & Pothole Issues',
        probability: 0.4,
        confidence: 0.6,
        risk_score: 0.4,
        reasoning: 'General risk assessment based on location and historical data',
        recommended_actions: ['Regular road inspections', 'Preventive maintenance'],
        timeframe
      },
      {
        category: 'Water Supply',
        probability: 0.3,
        confidence: 0.5,
        risk_score: 0.3,
        reasoning: 'Standard risk level for water-related issues',
        recommended_actions: ['Monitor water pressure', 'Check infrastructure'],
        timeframe
      }
    ];

    const riskAreas = [
      {
        location: location,
        risk_level: 'medium',
        risk_score: 0.35,
        predicted_issues: ['Road & Pothole Issues', 'Water Supply'],
        population_density: 2500
      }
    ];

    return {
      success: true,
      data: {
        predictions,
        risk_areas: riskAreas,
        overall_risk_score: 0.35,
        weather_context: null,
        historical_context: null,
        model_info: {
          models_used: ['fallback'],
          last_trained: new Date().toISOString(),
          version: 'fallback-1.0.0'
        },
        generated_at: new Date().toISOString()
      },
      fallback: true
    };
  }

  /**
   * Format predictions for the existing API response format
   * @param {Object} mlResponse - Response from ML service
   * @returns {Object} Formatted response
   */
  formatPredictionsResponse(mlResponse) {
    if (!mlResponse.success) {
      return {
        success: false,
        message: mlResponse.message || 'Failed to generate predictions',
        data: null
      };
    }

    const data = mlResponse.data;
    
    return {
      success: true,
      data: {
        predictedIssueTypes: data.predictions || [],
        highRiskAreas: data.risk_areas || [],
        riskScore: data.overall_risk_score || 0,
        recommendations: this.extractRecommendations(data.predictions || []),
        aiInsights: {
          confidence: this.calculateAverageConfidence(data.predictions || []),
          modelAccuracy: 85.2, // This could come from model_info
          anomalyDetection: [],
          correlationMatrix: {}
        },
        weather_context: data.weather_context,
        historical_context: data.historical_context,
        generatedAt: data.generated_at,
        aiModel: data.model_info?.models_used?.join(', ') || 'ML Engine',
        dataPoints: 5000 // This could come from historical context
      }
    };
  }

  /**
   * Extract recommendations from predictions
   * @param {Array} predictions - Array of predictions
   * @returns {Array} Array of recommendations
   */
  extractRecommendations(predictions) {
    const recommendations = [];
    
    predictions.forEach(prediction => {
      if (prediction.recommended_actions) {
        prediction.recommended_actions.forEach(action => {
          recommendations.push({
            type: 'action',
            message: action,
            priority: prediction.risk_score > 0.7 ? 'high' : 'medium',
            category: prediction.category
          });
        });
      }
    });

    return recommendations;
  }

  /**
   * Calculate average confidence from predictions
   * @param {Array} predictions - Array of predictions
   * @returns {number} Average confidence
   */
  calculateAverageConfidence(predictions) {
    if (!predictions.length) return 0;
    
    const totalConfidence = predictions.reduce((sum, pred) => sum + (pred.confidence || 0), 0);
    return Math.round((totalConfidence / predictions.length) * 100);
  }
}

module.exports = new MLIntegrationService();
